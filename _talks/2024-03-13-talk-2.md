---
title: "Linear Algebra v2: Regression and SVD?"
collection: talks
type: "Talk"
permalink: /talks/2024-03-05-talk-2
venue: "University of Virginia, STEM for Virgina "
date: 2024-03-05
location: "Charlottesville, Virginia"
---

Building off of my first talk, I will couple linear algebra and calculus to introduce the idea of the *cost function* along with the simple technique of linear regression. We'll then revisit eigenvectors and values while briefly describing how to systematically find them. The Google Page Rank algorithm will also be shown again, this time with the numerical calculations of finding the eigenvector associated with $\lambda = 1$. From there, we'll touch on the singular value decomposition (SVD), one of the most important linear algebraic tools given its utility for dimensionality reduction and look at image compression using the technique. 

[Associated Jupyter Notebook Here](https://github.com/mohan-s1/mohan-s1.github.io/blob/28b6b5bcdb96ff47cc1bc7cc4a7a2350f2410ef9/_talks/linalg_talk/linalg_talk.ipynb)

**Note.** For the code to work, you'll have to download the image titled `tundy.jpeg` while everything else is used in the markdown cells. Useful, but technically extraneous.
